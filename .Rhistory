library(RSelenium)
library(jsonlite)
library(stringr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(tidyquant)
cases <- c(
"Chroma Case", "Chroma 2 Case", "Falchion Case"
)
casesfinal <- c(
"Chroma Case", "Chroma 2 Case", "Falchion Case", "Shadow Case",
"Revolver Case", "Operation Wildfire Case", "Chroma 3 Case",
"Gamma Case", "Gamma 2 Case", "Glove Case", "Spectrum Case",
"Operation Hydra Case", "Spectrum 2 Case", "Clutch Case",
"Horizon Case", "Danger Zone Case", "Prisma Case", "CS20 Case",
"Shattered Web Case", "Prisma 2 Case", "Fracture Case",
"Operation Broken Fang Case", "Snakebite Case",
"Operation Riptide Case", "Dreams & Nightmares Case",
"Recoil Case", "Revolution Case", "Kilowatt Case", "Gallery Case"
)
scrape_case_chart_data <- function(case_name, remDr, wait_time = 6) {
encoded_case <- URLencode(case_name)
url <- paste0("https://steamcommunity.com/market/listings/730/", encoded_case)
remDr$navigate(url)
Sys.sleep(wait_time)
html <- remDr$getPageSource()[[1]]
html_clean <- gsub("[\r\n\t]", "", html)
pattern <- "var line1=\\[(\\[.*?\\])\\];"
matches <- stringr::str_match(html_clean, pattern)
if (is.na(matches[2])) {
message(paste("❌ Could not extract line1 for:", case_name))
return(NULL)
}
json_array <- paste0("[", matches[2], "]")
chart_data <- tryCatch({
fromJSON(json_array)
}, error = function(e) {
message(paste("❌ JSON parse error for", case_name, ":", e$message))
return(NULL)
})
num_cols <- ncol(chart_data)
df <- tibble(
time = chart_data[, 1],
price_usd = as.numeric(chart_data[, 2]),
volume = if (num_cols >= 3) as.numeric(chart_data[, 3]) else NA_real_
) %>%
mutate(
time_clean = str_remove(time, " \\+0$"),
date = parse_date_time(time_clean, orders = "b d Y H", tz = "UTC"),
Case = case_name
) %>%
select(Case, date, price_usd, volume) %>%
filter(!is.na(date))
return(df)
}
# Start
rD <- rsDriver(browser = "firefox", chromever = NULL, verbose = FALSE)
remDr <- rD$client
# Scrape
all_data <- purrr::map_dfr(cases, ~ scrape_case_chart_data(.x, remDr))
# Stop
remDr$close()
rD$server$stop()
all_data_clean <- all_data %>%
mutate(date = as.POSIXct(date, tz = "UTC"))
daily_closes <- all_data_clean %>%
mutate(
hour = hour(date),
day = as.Date(date)
) %>%
filter(hour == 1) %>%  # Keep only rows with time == 1:00
group_by(Case, day) %>%  # In case multiple entries at 1:00, just in case
slice_max(order_by = date, n = 1) %>%
ungroup() %>%
select(Case, date, price_usd, volume) %>%
arrange(Case, date)
past_month <- all_data_clean %>%
filter(date >= Sys.Date() - months(1)) %>%
group_by(Case) %>%
arrange(date) %>%
slice(-1) %>%  # removes the first row of each group
ungroup()
fx_usdcad <- tq_get("CAD=X", get = "stock.prices", from = "2010-01-01")
fx_usdcad_clean <- fx_usdcad %>%
select(date, fx_rate = close)
fx_usdcad_filled <- fx_usdcad_clean %>%
complete(date = seq.Date(min(date), max(date), by = "day")) %>%
fill(fx_rate, .direction = "down")
CAD_Converted <- all_data_clean %>%
mutate(date_only = as.Date(date)) %>%
left_join(fx_usdcad_filled, by = c("date_only" = "date")) %>%
mutate(price_cad = price_usd * fx_rate) %>%
drop_na()
CAD_Selected <- CAD_Converted %>%
select(Case, date, price_cad, volume)
Daily_CAD <- CAD_Selected %>%
mutate(
hour = hour(date),
day = as.Date(date)
) %>%
filter(hour == 1) %>%  # Keep only rows with time == 1:00
group_by(Case, day) %>%  # In case multiple entries at 1:00, just in case
slice_max(order_by = date, n = 1) %>%
ungroup() %>%
select(Case, date, price_cad, volume) %>%
arrange(Case, date)
Month_CAD <- CAD_Selected %>%
filter(date >= Sys.Date() - months(1)) %>%
group_by(Case) %>%
arrange(date) %>%
slice(-1) %>%  # removes the first row of each group
ungroup()
library(lubridate)
#' Before running the app, scrape data first
#'
#' This function stores data in a global variable that will be used by the app
#'
#' @param use_real_data Logical, whether to scrape real data (TRUE) or use sample data (FALSE)
#' @param cases Character vector of case names to scrape
#' @return None, data is stored in global variables
scrape_and_prepare_data <- function(use_real_data = FALSE, cases = c("Chroma Case", "Chroma 2 Case", "Falchion Case")) {
# Define scraping function
scrape_case_chart_data <- function(case_name, remDr, wait_time = 6) {
message(paste("Scraping data for", case_name))
encoded_case <- URLencode(case_name)
url <- paste0("https://steamcommunity.com/market/listings/730/", encoded_case)
remDr$navigate(url)
Sys.sleep(wait_time)
html <- remDr$getPageSource()[[1]]
html_clean <- gsub("[\r\n\t]", "", html)
pattern <- "var line1=\\[(\\[.*?\\])\\];"
matches <- stringr::str_match(html_clean, pattern)
if (is.na(matches[2])) {
message(paste("❌ Could not extract line1 for:", case_name))
return(NULL)
}
json_array <- paste0("[", matches[2], "]")
chart_data <- tryCatch({
fromJSON(json_array)
}, error = function(e) {
message(paste("❌ JSON parse error for", case_name, ":", e$message))
return(NULL)
})
num_cols <- ncol(chart_data)
df <- tibble(
time = chart_data[, 1],
price_usd = as.numeric(chart_data[, 2]),
volume = if (num_cols >= 3) as.numeric(chart_data[, 3]) else NA_real_
) %>%
mutate(
time_clean = str_remove(time, " \\+0$"),
date = parse_date_time(time_clean, orders = "b d Y H", tz = "UTC"),
Case = case_name
) %>%
select(Case, date, price_usd, volume) %>%
filter(!is.na(date))
return(df)
}
# Get the data - either real or sample
if (use_real_data) {
message("Starting RSelenium... this may take a moment")
rD <- rsDriver(browser = "firefox", chromever = NULL, verbose = FALSE)
remDr <- rD$client
# Create a list to store data for each case
all_data_list <- list()
# Scrape data for each case sequentially
for (case_name in cases) {
case_data <- scrape_case_chart_data(case_name, remDr)
if (!is.null(case_data)) {
all_data_list[[case_name]] <- case_data
message(paste("✓ Successfully scraped data for", case_name))
}
}
# Close Selenium
message("Closing RSelenium session")
remDr$close()
rD$server$stop()
# Combine all data
all_data <- bind_rows(all_data_list)
} else {
message("Using sample data")
# Generate sample data with more realistic price movements
set.seed(123)
# Generate dates for the sample data
dates <- seq(as.POSIXct("2023-01-01"), as.POSIXct("2023-04-10"), length.out = 100)
# Create sample data
all_data <- tibble()
for (case_name in cases) {
message(paste("Generating sample data for", case_name))
# Generate a base price for this case
base_price <- runif(1, 0.5, 5)
# Generate price movements with some trend and volatility
prices <- numeric(length(dates))
prices[1] <- base_price
for (i in 2:length(dates)) {
# Random walk with slight upward bias
prices[i] <- max(0.1, prices[i-1] * (1 + rnorm(1, mean = 0.002, sd = 0.02)))
}
# Generate volumes with some correlation to price changes
volumes <- round(runif(length(dates), 1000, 20000))
# Add random spikes in volume
spike_indices <- sample(1:length(dates), 5)
volumes[spike_indices] <- volumes[spike_indices] * runif(length(spike_indices), 2, 5)
# Create the data frame for this case
case_data <- tibble(
Case = case_name,
date = dates,
price_usd = prices,
volume = volumes
)
# Append to the main data frame
all_data <- bind_rows(all_data, case_data)
}
}
message("Processing data...")
# Clean data
all_data_clean <- all_data %>%
mutate(date = as.POSIXct(date, tz = "UTC"))
# Get exchange rates
message("Getting exchange rates...")
fx_usdcad <- tryCatch({
tq_get("CAD=X", get = "stock.prices", from = "2023-01-01")
}, error = function(e) {
message("Using sample exchange rate data")
# Create sample exchange rate data if API call fails
tibble(
date = seq.Date(as.Date("2023-01-01"), as.Date("2023-04-10"), by = "day"),
close = runif(100, 1.25, 1.35)
)
})
fx_usdcad_clean <- fx_usdcad %>%
select(date, fx_rate = close)
fx_usdcad_filled <- fx_usdcad_clean %>%
complete(date = seq.Date(min(date), max(date), by = "day")) %>%
fill(fx_rate, .direction = "down")
# Convert to CAD
message("Converting prices to CAD...")
CAD_Converted <- all_data_clean %>%
mutate(date_only = as.Date(date)) %>%
left_join(fx_usdcad_filled, by = c("date_only" = "date")) %>%
mutate(price_cad = price_usd * fx_rate) %>%
drop_na()
# Check if we have data after join
message(paste("Number of rows in CAD_Converted:", nrow(CAD_Converted)))
# If we have no data after join, create some using a fixed rate
if(nrow(CAD_Converted) == 0) {
message("No data after join, creating sample CAD data")
CAD_Converted <- all_data_clean %>%
mutate(
date_only = as.Date(date),
price_cad = price_usd * 1.3 # Use a fixed exchange rate
)
}
# Select relevant columns
CAD_Selected <- CAD_Converted %>%
select(Case, date, price_cad, volume)
# Create daily data
message("Creating daily data...")
Daily_CAD <- CAD_Selected %>%
mutate(
hour = hour(date),
day = as.Date(date)
) %>%
group_by(Case, day) %>%
slice_max(order_by = date, n = 1) %>%
ungroup() %>%
select(Case, date, price_cad, volume) %>%
arrange(Case, date)
# Debug info
message("Data preparation complete!")
message(paste("Available cases:", paste(unique(Daily_CAD$Case), collapse = ", ")))
message(paste("Total data points:", nrow(Daily_CAD)))
# Return the prepared data
return(Daily_CAD)
}
source("~/.active-rstudio-document", echo=TRUE)
library(shiny); runApp('CS2_App_Refined.R')
runApp('CS2_App_Refined.R')
